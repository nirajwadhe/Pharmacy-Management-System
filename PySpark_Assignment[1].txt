Year,Quarter,Average revenue per seat,total no. of booked seats

Q.1) How can you calculate the average revenue per seat for each year and quarter?

>>> dataRDD=sc.textFile("hdfs://nameservice1/user/cdacbdhnov057/training/airlines.csv")                          
>>> dataRDD.take(10)                                                                                             
['Year,Quarter,Average revenue per seat,total no. of booked seats', '1995,1,296.9,46561', '1995,2,296.8,37443', '
1995,3,287.51,34128', '1995,4,287.78,30388', '1996,1,283.97,47808', '1996,2,275.78,43020', '1996,3,269.49,38952',
 '1996,4,278.33,37443', '1997,1,283.4,35067']                                                                    

>>> header=dataRDD.first()                                                                                       
>>> print(header)                                                                                                
Year,Quarter,Average revenue per seat,total no. of booked seats                                                  

>>> splitRDD=dataRDD.filter(lambda a: a!=header)                                                                 
>>> splitRDD.take(10)                                                                                            
['1995,1,296.9,46561', '1995,2,296.8,37443', '1995,3,287.51,34128', '1995,4,287.78,30388', '1996,1,283.97,47808',
 '1996,2,275.78,43020', '1996,3,269.49,38952', '1996,4,278.33,37443', '1997,1,283.4,35067', '1997,2,289.44,46565'
]                                                                                                                

>>> splitRDD=splitRDD.map(lambda a: a.split(','))                                                                
>>> splitRDD.take(10)                                                                                            
[['1995', '1', '296.9', '46561'], ['1995', '2', '296.8', '37443'], ['1995', '3', '287.51', '34128'], ['1995', '4'
, '287.78', '30388'], ['1996', '1', '283.97', '47808'], ['1996', '2', '275.78', '43020'], ['1996', '3', '269.49',
 '38952'], ['1996', '4', '278.33', '37443'], ['1997', '1', '283.4', '35067'], ['1997', '2', '289.44', '46565']]  
                                    
>>> mapRDD=splitRDD.map(lambda a: ((int(a[0]), int(a[1])), float(a[2])))                                         
>>> mapRDD.take(10)                                                                                              
[((1995, 1), 296.9), ((1995, 2), 296.8), ((1995, 3), 287.51), ((1995, 4), 287.78), ((1996, 1), 283.97), ((1996, 2
), 275.78), ((1996, 3), 269.49), ((1996, 4), 278.33), ((1997, 1), 283.4), ((1997, 2), 289.44)]

Q.2)What is the PySpark code to find the year and quarter with the highest average revenue per seat?

>>> sortval=mapRDD.sortBy(lambda a: -a[1]) 
>>> sortval.take(1)
[((2014, 3), 396.37), ((2014, 2), 395.62), ((2014, 4), 392.66), ((2013, 3), 390.04), ((2015, 1), 388.32), ((2015,
 2), 385.91), ((2012, 2), 384.67), ((2014, 1), 382.15), ((2013, 4), 382.04), ((2013, 2), 378.0)] 

Q.3)How can you calculate the total number of booked seats for each year and quarter?

>>> totseats=splitRDD.map(lambda a: ((int(a[0]), int(a[1])), int(a[3])))                                         
>>> totseats.take(10)                                                                                            
[((1995, 1), 46561), ((1995, 2), 37443), ((1995, 3), 34128), ((1995, 4), 30388), ((1996, 1), 47808), ((1996, 2), 
43020), ((1996, 3), 38952), ((1996, 4), 37443), ((1997, 1), 35067), ((1997, 2), 46565)] 


Q.4)What is the PySpark code to determine the year and quarter with the highest total number of booked seats?

>>> sortval1=totseats.sortBy(lambda a: -a[1])                                                                    
>>> sortval1.take(1)                                                                                            
[((2010, 1), 49678), ((2013, 1), 49143), ((2004, 1), 49022), ((2000, 1), 48159), ((2014, 4), 47928), ((1996, 1), 
47808), ((2007, 2), 47758), ((2005, 4), 47608), ((1999, 1), 47453), ((2008, 1), 46885)]                                                                                                            

Q.5)How can you calculate the total revenue generated for each year and quarter (revenue = average revenue per seat * total number of booked seats)?

>>> totrev=splitRDD.map(lambda a: ((int(a[0]), int(a[1])), float(a[2])*int(a[3])))                               
>>> totrev.take(10)                                                                                              
[((1995, 1), 13823960.899999999), ((1995, 2), 11113082.4), ((1995, 3), 9812141.28), ((1995, 4), 8745058.639999999
), ((1996, 1), 13576037.760000002), ((1996, 2), 11864055.6), ((1996, 3), 10497174.48), ((1996, 4), 10421510.19), 
((1997, 1), 9937987.799999999), ((1997, 2), 13477773.6)]   

Q.6)What is the PySpark code to identify the year and quarter with the highest total revenue?

>>> sortval2=totrev.sortBy(lambda a: -a[1])                                                                      
>>> sortval2.take(1)                                                                                            
[((2014, 4), 18819408.48), ((2013, 1), 18572613.990000002), ((2013, 3), 18177814.2), ((2015, 2), 17316167.61), ((
2000, 1), 16385136.57), ((2010, 1), 16300345.36), ((2012, 4), 16087025.010000002), ((2014, 3), 15956667.09), ((20
12, 3), 15947048.32), ((1999, 1), 15742058.22)]  

Q.7)How can you find the average revenue per seat across different years using PySpark?
                                                                            
>>> mapRDD1 = splitRDD.map(lambda a: (int(a[0]), float(a[2])))                                                   
>>> mapRDD1.take(10)                                                                                             
[(1995, 296.9), (1995, 296.8), (1995, 287.51), (1995, 287.78), (1996, 283.97), (1996, 275.78), (1996, 269.49), (1
996, 278.33), (1997, 283.4), (1997, 289.44)]                                                                     

>>> sortbyval = mapRDD1.reduceByKey(lambda a,b: a+b)
>>> sortbyval.take(10)        
>>> val = sortbyval.map(lambda a: (int(a[0]), float(a[1]/4)))                                                                                                                        
>>> val.take(10)                                                                                                                                                      
    

Q.8)What is the PySpark code to determine the year with the highest average revenue per seat?

>>> sortval3 = val.sortBy(lambda a: -a[1])                                                                 
>>> sortval3.take(1)                                                                                            


Q.9)How can you calculate the overall average revenue per seat for the entire dataset using PySpark?

>>> avgRDD=splitRDD.map(lambda a: float(a[2])).mean()                                                            
>>> avgRDD
329.7475  
